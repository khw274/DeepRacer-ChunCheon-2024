# 2024년 AWS DeepRacer Championship 춘천
제2회 AWS DeepRacer Championship 춘천

```🏆최우수상, 춘천시장상🏆```  

<img src="https://github.com/user-attachments/assets/7519adc3-5552-4e77-aa97-45ecb41c2860" width="320" height="470"/>

## 공모 내용
 AWS DeepRacer를 활용한 인공지능 강화학습 기반의 자율주행 자동차 AI 융합 경진대회

## 대회 진행
### 트랙
#### 예선: Smile Speedway(Counterclockwise)  
![image](https://github.com/user-attachments/assets/d161e888-154e-4c00-9ed1-1a01d58de8a8)

#### 본선: 2022 re:Invent Championship(Counterclockwise)
![image](https://github.com/user-attachments/assets/3c56e19b-9998-4c72-afe8-24c2dc911885)

#### 결승: RL Speedway(Counterclockwise)
![image](https://github.com/user-attachments/assets/1a3fdb49-e7c1-424c-be80-45acec33cad9)

### 규칙
- 1바퀴 완주 기록 기준 (트랙 이탈 시 3초 패널티)   
- 모델 훈련시간 : 30시간  
- 모델 제출 제한 횟수 : 50회

## 예선
작년에 참가했던 2023년 인천 딥레이서 챔피언십에서 사용한 트랙 Smile Speedway와 같은 트랙이라 좀 더 수월할 것이라 예상하고 예선전에 임하였다.

하지만 예상과 달리 같은 코드와 파라미터, 조향각을 사용했음에도 좋은 랩타임이 나오지 않아 별도의 수정 과정을 거쳤다.

변경사항은 총 4가지로 코드 최적화, 코드 파라미터 수정, 조향각과 속도 수정, 하이퍼 파라미터 수정이다.

### 코드 최적화) 
이전에 사용하던 코드는 여러 테스트들이 묶여 있어 현재 AWS 시스템에서 사용이 안되는 것을 확인하였다.

테스트 하는 부분은 실제 작동하는데 영향을 끼치지 않아 모두 삭제하였고 더 직관적인 코드를 구성할 수 있었다.

### 코드 파라미터 수정)
훈련에 사용하는 보상함수 코드에는 다음과 같은 주요 세가지 파라미터 수정 포인트가 있다.

#### 1. get_target_point 함수의 r 값:
설정한 값: r = params['track_width'] * 0.45  
파라미터 설명: 이 반지름(r)은 차량의 위치를 기준으로 웨이포인트가 "안쪽" 또는 "바깥쪽"에 있는지 판단하는 데 사용된다. 이 값을 조정하면 차량이 트랙의 중앙선을 얼마나 가깝게 따라야 하는지를 변경할 수 있다.  

수정 포인트: 현재 0.45로 설정된 배수를 늘리거나 줄이면 트랙을 따르는 "밀도"가 바뀌게 된다. 더 큰 값은 차량이 트랙의 중앙을 더 가깝게 따르도록 하고, 더 작은 값은 차량이 더 느슨하게 트랙을 따르도록 할 수 있다.  

#### 2. up_sample 함수의 factor 값:
설정한 값: up_sample(waypoints, 20)  
설명: 이 factor는 추가한 최적좌표 웨이포인트 사이사이에 얼마나 더 많은 웨이포인트들을 추가할지를 제어한다. 더 높은 값은 기존 웨이포인트 사이에 더 많은 웨이포인트를 추가하여 경로 계획을 부드럽게 하지만 계산 부하가 증가한다.  

수정 포인트: 이 값을 조정하면 웨이포인트의 밀도가 변경된다. 더 높은 값은 차량이 경로를 더 부드럽게 따라가게 만들 수 있지만 계산 속도가 느려질 수 있다. 반대로 더 낮은 값은 덜 정밀하지만 계산이 더 빨라질 수 있다.  

#### 3. score_steer_to_point_ahead 함수의 오류 스케일링:
현재 수식: error = (steering_angle - best_steering_angle) / 60.0  
설명: 이 줄은 현재 조향 각도와 최적 조향 각도 간의 오차를 계산하며, 60.0으로 나누어 스케일링한다. 이 스케일링 값은 원하는 조향 각도에 대한 오류를 얼마나 크게 패널티로 처리할지를 결정한다.  

수정 포인트: 60.0을 다른 값으로 변경하면 조향 오류에 대한 보상 민감도가 조정된다. 더 작은 값을 사용하면 함수가 조향 오류에 대해 더 민감하게 반응하여 더 정확한 조향을 유도할 수 있고, 더 큰 값은 오류에 대해 더 관대하게 반응하게 됩니다.

이렇게 세가지 파라미터들을 설정한 조향각과 속도에 맞게 다양한 테스트 시나리오를 세워가면서 훈련을 했고 최적의 파라미터를 찾을 수 있었다.

### 조향각과 속도 수정)
![image](https://github.com/user-attachments/assets/be43cd1c-3bec-4c74-bb64-b6b242f6a5b4)

훈련을 시작하면 훈련과 평가 과정을 거쳐서 보상함수 훈련 그래프가 형성이 된다.

그와 함께 차량의 주행 시뮬레이션 영상을 보여주는데 트랙의 어느 구간에서 이탈하는지 속도를 줄이는 구간은 어딘지를 명확히 확인할 수 있다.

이를 참고하면서 조향각과 속도를 수정하였다.

Smile Speedway 트랙은 비교적 쉬운 트랙이지만 굴곡이 큰 커브일 때와 반복되는 완만한 커브일 때를 모두 가지고 있기에 조향각 설정이 중요하다.

내가 사용하는 최적좌표 코드는 인코스를 타는 대신 트랙을 이탈할 확률이 높아지기 때문에 굴곡이 있는 커브일 시에는 속도를 확실히 낮추고 완만한 커브일 때는 굴곡 있는 커브일 때보다 최대속도를 높여 빠른 랩타임을 기록할 수 있도록 했다.

### 하이퍼 파라미터 수정)
![image](https://github.com/user-attachments/assets/639d7f6b-fb26-4cf7-90d6-0286f8f59876)

하이퍼 파라미터 중 수정한 부분은 Entropy와 Discount factor이다. 

#### - Entropy:
훈련 시 다양한 행동을 유도하기 위해 설정하는 장치가 있는데, 이 값을 크게 설정하면 훈련 시 더 많은 실험을 하게 된다. 

더 많은 실험을 통해 다양한 행동을 할 수 있지만, 훈련 시간이 길어지고 완주율이 낮아질 수 있다.

기본 값은 0.01로 설정되어 있는데, 더 다양한 시도를 할 수 있도록 0.03으로 훈련을 시작했다.  

훈련한 모델을 복제하여 훈련 시간이 2시간을 넘어갈 때(훈련당 1시간으로 가정하고, 3번째 훈련을 시작할 때) 값을 0.003으로 극단적으로 줄여, 지금까지 훈련한 데이터를 기반으로 훈련하도록 설정했다.

훈련이 어느 정도 안정되면 더 이상의 다양한 시도를 하지 않는 것이 좋다고 판단한 결과이다.

#### - Discount factor:
  목표를 달성하는 데 걸리는 시간에 대해 얼마나 신경 쓰는지를 조정한다. 값을 크게 설정하면 장기적인 보상에 집중하고 낮게 설정하면 즉각적인 보상에 집중하게 된다.

  기본으로 설정된 값은 0.99로 훈련이 너무 장기화되지 않도록 0.7로 값을 줄여서 훈련을 진행하였다.

### 예선 결과
![image](https://github.com/user-attachments/assets/c7784a68-880e-4a0b-aab7-c8472931506c)

랩타임 8.859의 기록을 세웠고 2등으로 예선을 마무리 지었다.

## 본선
본선은 예선과는 다른 트랙으로 2022 re:Invent Championship 트랙이다.

여태까지 경험하지 못한 트랙이기도 하고 복잡한 커브들로 이루어져있어 훈련을 하는데 어려움을 겪었다.

예선과 같이 코드 파라미터 수정, 조향각과 속도 수정, 하이퍼 파라미터 수정 작업을 거치면서 가장 최적화된 모델을 연구했다.

최종적으로 가장 주요하게 수정한 부분은 조향각과 속도이다. 

### 조향각과 속도 수정)
![image](https://github.com/user-attachments/assets/c3272503-829c-414d-b547-6b92fc649376)

코드 파라미터와 하이퍼 파라미터를 여러 시나리오를 세워 변경하며 훈련해보았지만 훈련 그래프가 잘 올라가지 않고 기록 또한 좋지 않았다.

예선 트랙에 비해 더 굴곡이 심하고 많아진 커브로 인해 완주율이 급격히 낮아진 것을 확인할 수 있었다.

따라서 커브 구간에서의 속도를 크게 낮추었고 직진 속도를 3개로 구분하였다.

직진 속도를 3개로 구분한 이유는 크게 두가지로 다음과 같다.

1. 직진 구간에서 확실히 속도를 내기 위해
2. 속도를 2개로만 나누면 커브 구간에서 이탈할 확률이 높기 때문

예선에서 사용한 코드 파라미터와 하이퍼 파라미터를 사용했고 위와 같은 조향각과 속도를 적용하여 안정적인 모델을 훈련할 수 있었다.

### 훈련 방법과 그래프
총 5시간의 훈련을 진행하였고 예선과 마찬가지로 2시간 이후의 훈련부터는 Entropy를 0.003으로 낮추어 진행하였다.

추가적으로 마지막 5시간째 훈련 때 직진 속도를 0.2 씩 증가시켜 더 빠른 속도로 주행할 수 있도록 훈련시켰다.

#### - 처음 1시간 훈련한 모델의 훈련 그래프이다. (Entropy 0.03)
![image](https://github.com/user-attachments/assets/0087a6cb-98a9-43f6-95df-3c3b18ea4090)

#### - 2시간 훈련한 모델의 훈련 그래프이다. (Entropy 0.03)  
![image](https://github.com/user-attachments/assets/8ed09f62-186a-48ad-9fa2-333555aef47d)
 
#### - 3시간 훈련한 모델의 훈련 그래프이다. (Entropy 0.003)  
![image](https://github.com/user-attachments/assets/37f97a49-bc3b-4b1e-89b1-4e66cf299aa6)

#### - 4시간 훈련한 모델의 훈련 그래프이다. (Entropy 0.003)   
![image](https://github.com/user-attachments/assets/6e30264c-7b8e-497b-bc2d-2431c0b7fa4c)

#### - 5시간 훈련한 모델의 훈련 그래프이다. (Entropy 0.003, 직진 속도 +0.2)  
![image](https://github.com/user-attachments/assets/bff09bf6-c9ec-410e-aca0-98b618c98a71)

처음 목표로 한 17초대가 안정적으로 나오는 모델을 찾기 위해 여러번 clone을 만들어 훈련을 진행했고 완주율이 높을 때 훈련을 중지하는 식으로 훈련하였다.

### 본선 결과
![image](https://github.com/user-attachments/assets/2c0853e3-fab6-40d5-9721-155b4c172cba)

랩타임 16.796의 기록을 세웠고 5등으로 본선을 마무리 지었다.

### 예선과 본선에 대한 소견
예선 결과에 매우 만족스러웠다. 
사실 춘천 딥레이서는 인천 딥레이서보다 경쟁률이 훨씬 높아 쉽지 않을 것이라고 예상했다.   
하지만 Smile Speedway 트랙에 자신감이 있었고, 좋은 결과로 본선에 진출할 수 있어서 뿌듯했다.

본선에서는 결승에 진출했지만, 개인적으로는 아쉬움이 남는 결과였다. 16초대 기록이면 여유롭게 결승에 진출할 것이라고 안일하게 생각했던 부분이 아쉬웠다. 상위권 팀들은 15초대 기록을 달성했으며, 나도 더 빠른 속도로 설정하고 훈련했어야 했다는 생각이 들었다.

## 결승
결승 트랙은 RL SpeedWay로 본선과 같이 처음 경험해보는 트랙이다.

결승은 오프라인에서 진행하는 만큼 온라인 시뮬레이션 주행과 큰 차이가 나기 때문에 별도의 모델 제작이 필요했다.

최적 경로를 따라가는 코드와 중앙선을 중심으로 따라가는 코드를 사용해 두가지 경우의 수를 두고 훈련을 시작했다.

### 최적 경로 코드
최적 경로 코드는 온라인에서 기록이 훨씬 좋긴 하지만 훈련이 수월히 진행되지 않았다.

가장 안정된 모델이 평균 10초대를 기록하며 평가를 마무리 지었다.  
![image](https://github.com/user-attachments/assets/e080716e-75e0-4f4b-9294-f3f9ea805297)

전반적으로 예선, 본선에 비해 상당히 낮은 속도로 세팅했고 하이퍼 파리미터와 코드 값은 본선과 동일하게 세팅하였다.

### 중앙선 코드
중앙선 코드는 최적 경로 코드와 상반되게 상당히 높은 안정성을 보여주었지만 기록 자체는 느린 모습을 보여주었다.

최적 경로 코드보다 속도를 대폭 감소시켰고 오프라인 주행에서 최적 경로 코드가 적합하지 않은 경우가 있어 준비한 모델이다.

모든 평가에서 완주율 100프로를 보여주었고 평균 13초대를 기록했다.  
![image](https://github.com/user-attachments/assets/eec4ddcc-0d1b-4487-b859-772a49d81a17)

중앙선 코드의 특성상 한 구간을 지속적으로 따라가기 위해 좌우로 흔들릴 수 있어서 시야각을 0.8로 설정해 좀 더 안정적으로 주행하게 했다.

추가로 오류 스케일링 값을 기존보다 낮은 값 30으로 설정해 함수가 조향 오류에 대해 더 민감하게 반응하도록 해 더 정확한 조향을 유도했다.

### 과적합
오프라인 주행에서 가장 중요한 요소는 과적합이다.

과적합은 차량을 한 트랙에서 과도하게 훈련시켜 다른 트랙에서는 주행을 하지 못하는 현상이다.

과적합이 걸린 모델은 온라인에서는 상당히 좋은 기록을 낼 수 있지만 오프라인 트랙에서는 좋지 않은 모습을 보여준다.

아무래도 오프라인 트랙은 경우에 따라 축소시키기도 하고 온라인 트랙에 정확히 일치할 수 없기 때문이다.

그래서 보상함수 그래프를 더 신경써서 훈련시켰고 모델의 완주율이 100에 근접하면 훈련을 중지시켰다.

#### 결승 최적 경로 코드 그래프  
![image](https://github.com/user-attachments/assets/155eef5b-69b6-469c-bb1f-353bdcdf78ef)

#### 결승 중앙성 코드 그래프
![image](https://github.com/user-attachments/assets/0bd4c8bf-2f7b-46a6-9bfd-68a37417d281)

### 결승 주행 및 결과
1차 테스트 주행에서 최적 경로 모델로 주행을 시작했지만 커브 구간에서 이탈이 잦고 오프라인 트랙에 적합하지 않은 모습을 보여주었다.

이 경우를 대비해 준비한 중앙선 모델로 2차 테스트 주행을 진행했다.

이전 모델보다 훨씬 안정적이고 완주율도 높게 측정됐다. 최적 경로 모델보다 훈련도 쉽고 기록도 느리지만 오프라인 트랙에서 성능이 훨씬 좋은 것을 보면서 온라인과 오프라인의 차이를 극명하게 느낄 수 있었다.

최종 모델 slow3-3의 오프라인 주행 최고 기록 영상이다.

https://github.com/user-attachments/assets/cad18361-f90d-4dde-9e19-76b1a5d75d47

첫번째 커브 구간에서 테스트 주행보다 좋지 않은 기록을 보여줬지만 두번째 커브 구간에서 시간을 단축할 수 있었다.

최종적으로 12.653의 랩타임으로 결승 주행을 마무리 지었다.



