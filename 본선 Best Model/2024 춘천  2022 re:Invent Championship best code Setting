Action space type: Discrete

Action space
No.
        Steering angle (Â°)    Speed (m/s)
0	-26.0	              1.00
1	-26.0	      	      1.20
2	-13.0	              1.40
3	-13.0	              1.80
4	  0.0	              1.90
5	  0.0	              2.20
6	  0.0	              2.80
7	 13.0	              1.40
8	 13.0 	              1.80
9	 26.0	              1.00
10	 26.0	              1.20

(Hyperparameter)                                                        (Value)
Gradient descent batch size	                                        64
Entropy	                                                             	0.03       
Discount factor	                                                 	0.7
Loss type	                                                        Huber
Learning rate	                                                        0.0003
Number of experience episodes between each policy-updating iteration    20
Number of epochs	                                                10
